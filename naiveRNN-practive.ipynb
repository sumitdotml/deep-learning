{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "in_layer = 5\n",
    "hidden_layer = 10\n",
    "out_layer = 6\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, in_layer) # the input\n",
    "\n",
    "W_xh = nn.Parameter(torch.randn(in_layer, hidden_layer))\n",
    "W_hh = nn.Parameter(torch.randn(hidden_layer, hidden_layer))\n",
    "bias_h = nn.Parameter(torch.randn(hidden_layer))\n",
    "W_hy = nn.Parameter(torch.randn(hidden_layer, out_layer))\n",
    "bias_o = nn.Parameter(torch.randn(out_layer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes for:\n",
      "\n",
      "W_xh: torch.Size([5, 10])\n",
      "W_hh: torch.Size([10, 10])\n",
      "bias_h: torch.Size([10])\n",
      "W_hy: torch.Size([10, 6])\n",
      "bias_o: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes for:\\n\\nW_xh: {W_xh.shape}\\nW_hh: {W_hh.shape}\\nbias_h: {bias_h.shape}\\nW_hy: {W_hy.shape}\\nbias_o: {bias_o.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5]),\n",
       " tensor([[[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002],\n",
       "          [-0.6092, -0.9798, -1.6091, -0.7121,  0.3037],\n",
       "          [-0.7773, -0.2515, -0.2223,  1.6871, -0.3206]],\n",
       " \n",
       "         [[-0.2993,  1.8793, -0.0721,  0.1578, -0.7735],\n",
       "          [ 0.1991,  0.0457, -1.3924,  2.6891, -0.1110],\n",
       "          [ 0.2927, -0.1578, -0.0288,  2.3571, -1.0373]]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs over time after the loop:\n",
      "[tensor([[-2.0555, -1.3811, -1.0657,  1.9577, -0.5778,  4.1142],\n",
      "        [-0.1740, -1.6102, -4.0757, -1.3605,  3.4223,  0.0911]],\n",
      "       grad_fn=<AddBackward0>), tensor([[-2.2260, -4.2207, -0.9821, -0.9547,  1.1853, -0.3534],\n",
      "        [-1.6624, -4.9108,  3.6438, -3.0317, -0.0464, -2.9806]],\n",
      "       grad_fn=<AddBackward0>), tensor([[-1.7778, -4.7155,  2.8338, -2.0096,  0.2305, -4.6111],\n",
      "        [ 0.0421, -0.8879,  0.4081,  2.2047, -0.3403, -5.3536]],\n",
      "       grad_fn=<AddBackward0>)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 6]),\n",
       " tensor([[[-2.0555, -1.3811, -1.0657,  1.9577, -0.5778,  4.1142],\n",
       "          [-2.2260, -4.2207, -0.9821, -0.9547,  1.1853, -0.3534],\n",
       "          [-1.7778, -4.7155,  2.8338, -2.0096,  0.2305, -4.6111]],\n",
       " \n",
       "         [[-0.1740, -1.6102, -4.0757, -1.3605,  3.4223,  0.0911],\n",
       "          [-1.6624, -4.9108,  3.6438, -3.0317, -0.0464, -2.9806],\n",
       "          [ 0.0421, -0.8879,  0.4081,  2.2047, -0.3403, -5.3536]]],\n",
       "        grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t_prev = None\n",
    "\n",
    "outputs_over_time = []\n",
    "for t in range((x.shape[-2])):\n",
    "    if h_t_prev is None:\n",
    "        h_t_prev = torch.zeros(batch_size, hidden_layer)\n",
    "    x_t = x[:, t, :]\n",
    "    h_t_current = torch.tanh(\n",
    "        x_t @ W_xh + h_t_prev @ W_hh + bias_h\n",
    "    )\n",
    "\n",
    "    y_t = h_t_current @ W_hy + bias_o\n",
    "\n",
    "    outputs_over_time.append(y_t)\n",
    "    h_t_prev = h_t_current\n",
    "\n",
    "print(f\"Outputs over time after the loop:\\n{outputs_over_time}\\n\")\n",
    "\n",
    "output = torch.stack(outputs_over_time, dim=1)\n",
    "output.shape, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
